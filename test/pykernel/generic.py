# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0
import ttmlir.ir as ir
import ttmlir.dialects.func as func
import ttmlir.dialects.affine as affine
import ttmlir.dialects.arith as arith
from ttmlir.dialects import ttir, ttcore, ttkernel

# Create MLIR context and module
ctx = ir.Context()
ctx.allow_unregistered_dialects = True
with ctx, ir.Location.unknown():
    module = ir.Module.create()

    with ir.InsertionPoint(module.body):
        # Define function
        @func.FuncOp.from_py_func(
            ir.RankedTensorType.get([64, 128], ir.F32Type.get()),
            ir.RankedTensorType.get([64, 128], ir.F32Type.get()),
            ir.RankedTensorType.get([64, 128], ir.F32Type.get()),
        )
        def elementwise_add(lhs, rhs, output):
            # Create affine maps for elementwise operation
            # All operands use identity map: (d0, d1) -> (d0, d1)
            identity_map = ir.AffineMap.get_identity(2)
            indexing_maps = ir.ArrayAttr.get(
                [
                    ir.AffineMapAttr.get(identity_map),  # lhs
                    ir.AffineMapAttr.get(identity_map),  # rhs
                    ir.AffineMapAttr.get(identity_map),  # output
                ]
            )

            # All dimensions are parallel for elementwise
            parallel_attr = ttcore.ir.IteratorTypeAttr.get(
                ir.Context.current, ttcore.IteratorType.Parallel
            )
            iterator_types = ir.ArrayAttr.get([parallel_attr, parallel_attr])

            # Single compute thread
            thread_type = ttir.ThreadType.Compute
            thread_attr = ttir.ir.ThreadAttr.get(ir.Context.current, thread_type)
            threads = ir.ArrayAttr.get([thread_attr])

            # Grid configuration (1x1 for simple case)
            grid = ttcore.ir.GridAttr.get(ctx, [1, 1])

            # Block factors (no additional blocking)
            # block_factors = ir.DenseI64ArrayAttr.get([1, 1])
            block_factors = [1, 1]

            # Create the generic operation
            ttir.GenericOp(
                results_=[output.type],
                inputs=[lhs, rhs],
                outputs=[output],
                grid=grid,
                block_factors=block_factors,
                indexing_maps=indexing_maps,
                iterator_types=iterator_types,
                threads=threads,
                num_regions=0,
            )

            # Add region body
            # with ir.InsertionPoint(generic_op.regions[0].blocks.append()):
            # Block arguments are memrefs corresponding to inputs/outputs
            # block = generic_op.regions[0].blocks[0]
            # lhs_memref = block.add_argument(
            #     ir.MemRefType.get([64, 128], ir.F32Type.get())
            # )
            # rhs_memref = block.add_argument(
            #     ir.MemRefType.get([64, 128], ir.F32Type.get())
            # )
            # out_memref = block.add_argument(
            #     ir.MemRefType.get([64, 128], ir.F32Type.get())
            # )

            # Create nested loops for computation
            # In practice, this would be generated by later passes
            # For now, we'll just yield the result
            # ttir.YieldOp([out_memref])
            # pass

            # return generic_op.results_[0]


print(module)
